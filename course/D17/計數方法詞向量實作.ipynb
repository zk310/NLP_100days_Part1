{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 瞭解如何使用計數方法詞向量與SVD\n",
    "\n",
    "再將文字資料輸入模型進行自然語言任務之前，其中一項重要的前處理即為將字詞向量化(詞嵌入word embedding)。 而將詞向量化的方法有很多，這裡我們會著重在介紹如何使用計數方法來將字詞向量化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字詞前處理\n",
    "\n",
    "在進行字詞向量化之前，我們需要針對文本資料進行前置處理，將**文本資料分割成字詞(斷詞)**，再將分割後的**字詞轉換成字詞ID清單**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you say goodbye and i say hello.\n",
      "say\n",
      "word2idx={}\n",
      "idx=0\n",
      "-----------------\n",
      "you\n",
      "word2idx={'say': 0}\n",
      "idx=1\n",
      "-----------------\n",
      "i\n",
      "word2idx={'say': 0, 'you': 1}\n",
      "idx=2\n",
      "-----------------\n",
      ".\n",
      "word2idx={'say': 0, 'you': 1, 'i': 2}\n",
      "idx=3\n",
      "-----------------\n",
      "and\n",
      "word2idx={'say': 0, 'you': 1, 'i': 2, '.': 3}\n",
      "idx=4\n",
      "-----------------\n",
      "goodbye\n",
      "word2idx={'say': 0, 'you': 1, 'i': 2, '.': 3, 'and': 4}\n",
      "idx=5\n",
      "-----------------\n",
      "hello\n",
      "word2idx={'say': 0, 'you': 1, 'i': 2, '.': 3, 'and': 4, 'goodbye': 5}\n",
      "idx=6\n",
      "-----------------\n",
      "{'say': 0, 'you': 1, 'i': 2, '.': 3, 'and': 4, 'goodbye': 5, 'hello': 6}\n",
      "sentence=['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n",
      "[1, 0, 5, 4, 2, 0, 6, 3]\n",
      "Processed corpus: [[1 0 5 4 2 0 6 3]] \n",
      " word2idx: {'say': 0, 'you': 1, 'i': 2, '.': 3, 'and': 4, 'goodbye': 5, 'hello': 6} \n",
      " idx2word: {0: 'say', 1: 'you', 2: 'i', 3: '.', 4: 'and', 5: 'goodbye', 6: 'hello'}\n"
     ]
    }
   ],
   "source": [
    "#導入會使用的library\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "#定義前處理函式\n",
    "def preprocess(corpus: List[str], only_word: bool = False):\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    '''\n",
    "    word_dic = set()\n",
    "    processed_sentence = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        #將所有字詞轉為小寫\n",
    "        sentence = sentence.lower()\n",
    "        print(sentence)\n",
    "\n",
    "        #移除標點符號(可以依據使用狀況決定是否要移除標點符號)\n",
    "        if only_word:\n",
    "            pattern = r'[^\\W_]+'\n",
    "            sentence = re.findall(pattern, sentence)\n",
    "        else:\n",
    "            punctuation_list = ['.', ',', '!', '?']\n",
    "            for pun in punctuation_list:\n",
    "                sentence = sentence.replace(pun, ' '+pun)\n",
    "            sentence = sentence.split(' ')\n",
    "        \n",
    "        #添加字詞到字典中\n",
    "        word_dic |= set(sentence)\n",
    "        processed_sentence.append(sentence)\n",
    "    \n",
    "    \n",
    "    #建立字詞ID清單\n",
    "    word2idx = dict()\n",
    "    idx2word = dict()\n",
    "    for word in word_dic:\n",
    "        print(word)\n",
    "        if word not in word2idx:\n",
    "            idx = len(word2idx)\n",
    "            print(f\"word2idx={word2idx}\")\n",
    "            print(f\"idx={idx}\")\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "        print(\"-----------------\")\n",
    "\n",
    "            \n",
    "    print(word2idx)\n",
    "    \n",
    "    #將文本轉為ID型式\n",
    "    id_mapping = lambda x: word2idx[x]\n",
    "    \n",
    "    print(f\"sentence={sentence}\")\n",
    "    print(list(map(id_mapping, sentence)))\n",
    "    #print(list(map(id_mapping, 'goodbye')))\n",
    "    \n",
    "    corpus = np.array([list(map(id_mapping, sentence)) for sentence in processed_sentence])\n",
    "\n",
    "    return corpus, word2idx, idx2word\n",
    "\n",
    "#定義簡易文本資料(使用Ch17講義中的例子)\n",
    "corpus = ['You say goodbye and I say hello.']\n",
    "\n",
    "processed_corpus, word2idx, idx2word = preprocess(corpus)\n",
    "print(f'Processed corpus: {processed_corpus} \\n word2idx: {word2idx} \\n idx2word: {idx2word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共現矩陣\n",
    "將轉化處理過的文本資料轉化為共現矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_corpus =  [[1 0 5 4 2 0 6 3]]\n",
      "len(word2idx)=7\n",
      "word2idx={'say': 0, 'you': 1, 'i': 2, '.': 3, 'and': 4, 'goodbye': 5, 'hello': 6}\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "[1 0 5 4 2 0 6 3]\n",
      "8\n",
      "idx=0, word_id=1\n",
      "idx=1, word_id=0\n",
      "idx=2, word_id=5\n",
      "idx=3, word_id=4\n",
      "idx=4, word_id=2\n",
      "idx=5, word_id=0\n",
      "idx=6, word_id=6\n",
      "idx=7, word_id=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 2, 1, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1],\n",
       "       [2, 0, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定義共現矩陣函式\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    print(co_matrix)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "        print(sentence)\n",
    "        print(sentence_size)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            print(f\"idx={idx}, word_id={word_id}\")\n",
    "            \n",
    "            \n",
    "            for i in range(1, window_size+1):\n",
    "                left_idx = idx - i\n",
    "                right_idx = idx + i\n",
    "\n",
    "                if left_idx >= 0:\n",
    "                    left_word_id = sentence[left_idx]\n",
    "                    co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "                if right_idx < sentence_size:\n",
    "                    right_word_id = sentence[right_idx]\n",
    "                    co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix\n",
    "\n",
    "print(\"processed_corpus = \",processed_corpus)\n",
    "print(f\"len(word2idx)={len(word2idx)}\")\n",
    "print(f\"word2idx={word2idx}\")\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 1, 1],\n",
       "       [1, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 0, 1, 1, 2, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義共現矩陣函式\n",
    "# method two\n",
    "\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            left_idx = idx - window_size if idx - window_size >= 0 else 0\n",
    "            context_ids = sentence[left_idx:idx]\n",
    "            \n",
    "            for left_i, left_id in enumerate(context_ids):\n",
    "                co_matrix[word_id, left_id] += 1\n",
    "                co_matrix[left_id, word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量間相似度\n",
    "比較轉換為向量的字詞的方法有很多種，其中當要表示字詞的相似度時，最常使用的方法為餘弦相似度 (Cosine Similarity)\n",
    "\n",
    "$$\n",
    "sim(x,y) = \\frac{xy}{||x||||y||}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067726510136"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義餘弦相似度\n",
    "def cos_similarity(x: np.ndarray, y: np.ndarray, eps: float=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2)) + eps)\n",
    "    \n",
    "    return np.dot(nx,ny)\n",
    "\n",
    "# calculate the similarity between I and you\n",
    "cos_similarity(co_matrix[word2idx['i']], co_matrix[word2idx['you']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立可供查詢相似度的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入字詞，查詢與此字詞top_n相似的結果\n",
    "def top_k_similarity(query: str, word2idx: dict, idx2word: dict, word_matrix: np.ndarray, top_k: int=3):\n",
    "    # handle the situation of query word not in corpus\n",
    "    if query not in word2idx:\n",
    "        raise ValueError(f\"{query} is not found in input dictionary\")\n",
    "    \n",
    "    # handle the situation of top_k is the same as the amount of words\n",
    "    if top_k >= len(word2idx):\n",
    "        raise ValueError(f\"top_k needs to be less than the amount of words\")\n",
    "        \n",
    "    print(f\"[query] : {query}\")\n",
    "    query_id = word2idx[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    similarity_scores = np.zeros(len(word2idx))\n",
    "    for i in range(len(word2idx)):\n",
    "        similarity_scores[i] = cos_similarity(query_vec, word_matrix[i])\n",
    "\n",
    "    # remove query word\n",
    "    similarity_scores[query_id] = 0\n",
    "    filter_word2idx = dict([(k, v) for k, v in word2idx.items() if k != query])\n",
    "    filter_idx2word = dict([(k, v) for k, v in idx2word.items() if k != query_id])\n",
    "    \n",
    "    # sorting by similarity score\n",
    "    top_k_idx = (-similarity_scores).argsort()[:top_k]\n",
    "    top_k_word = [filter_idx2word[word_idx] for word_idx in top_k_idx]\n",
    "    \n",
    "    return dict(zip(top_k_word, similarity_scores[top_k_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query] : you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'and': 0.8660253941251803, 'i': 0.7071067726510136, '.': 0.49999999292893216}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_similarity('you', word2idx, idx2word, co_matrix, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正向點間互資訊(PPMI)\n",
    "由於共生矩陣在高頻字上的缺陷，而PMI中加入了兩字詞共同出現的機率與各自出現的機率的關係，以此解決高頻詞在共生矩陣上的缺陷。\n",
    "而PPMI即將PMI內會產生負值的情況排除(若出現負值則賦予0)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&PMI(x,y) = log_2\\frac{P(x,y)}{P(x)P(y)} = log_2\\frac{C(x,y)N}{C(x)C(y)} \\\\\n",
    "&PPMI(x,y) = max(0,PMI(x,y))\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義正向點間互資訊\n",
    "\n",
    "def ppmi(co_matrix: np.ndarray, eps: float=1e-8, verbose: bool=False):\n",
    "    M = np.zeros_like(co_matrix, dtype=np.float32)\n",
    "    print(\"M=\",M)\n",
    "    N = np.sum(co_matrix)\n",
    "    print(co_matrix)\n",
    "    print(\"N=\",N)\n",
    "    S = np.sum(co_matrix, axis=0)\n",
    "    print(\"S=\",S)\n",
    "    total = co_matrix.shape[0]*co_matrix.shape[1]\n",
    "    print(co_matrix.shape[0])\n",
    "    print(co_matrix.shape[1])\n",
    "    \n",
    "    \n",
    "\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(co_matrix.shape[0]):\n",
    "        for j in range(co_matrix.shape[1]):\n",
    "            pmi = np.log2(co_matrix[i, j]*N / (S[i]*S[j] + eps))\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % 10 == 0 or cnt == total:\n",
    "                    print(f\"{cnt}/{total} Done\")\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0 1 1 1 2 1 1]\n",
      " [1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 1 1]\n",
      " [1 0 0 0 0 0 1]\n",
      " [2 0 1 0 0 1 0]\n",
      " [1 1 1 0 1 0 0]\n",
      " [1 0 1 1 0 0 0]]\n",
      "N= 26\n",
      "S= [7 2 4 2 4 4 3]\n",
      "7\n",
      "7\n",
      "10/49 Done\n",
      "20/49 Done\n",
      "30/49 Done\n",
      "40/49 Done\n",
      "49/49 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-38c1be4b0b54>:21: RuntimeWarning: divide by zero encountered in log2\n",
      "  pmi = np.log2(co_matrix[i, j]*N / (S[i]*S[j] + eps))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.8930848, 0.       , 0.8930848, 0.8930848, 0.       ,\n",
       "        0.3081223],\n",
       "       [0.8930848, 0.       , 0.       , 0.       , 0.       , 1.7004397,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.7004397, 0.7004397,\n",
       "        1.1154772],\n",
       "       [0.8930848, 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        2.1154773],\n",
       "       [0.8930848, 0.       , 0.7004397, 0.       , 0.       , 0.7004397,\n",
       "        0.       ],\n",
       "       [0.       , 1.7004397, 0.7004397, 0.       , 0.7004397, 0.       ,\n",
       "        0.       ],\n",
       "       [0.3081223, 0.       , 1.1154772, 2.1154773, 0.       , 0.       ,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ppmi = ppmi(co_matrix, verbose=True)\n",
    "output_ppmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "觀察上面的PPMI輸出矩陣，可以發現大部分的元素都為0(稀疏矩陣)，因此可以發現此矩陣包含了許多無法提供訊息的元素，利用奇異值分解，將矩陣降維，並保存重要的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello in co-occurrence matrix: [1 0 1 1 0 0 0]\n",
      "hello in PPMI: [0.3081223 0.        1.1154772 2.1154773 0.        0.        0.       ]\n",
      "hello in SVD: [-0.5126197  -0.5698161  -0.39725903 -0.4323913  -0.01054526 -0.124419\n",
      " -0.22839099]\n"
     ]
    }
   ],
   "source": [
    "# 使用np的linalg.svd對PPMI矩陣進行奇異值分解\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(output_ppmi)\n",
    "\n",
    "# 使用SVD將將原本的稀疏向量轉變為稠密向量\n",
    "print(f\"hello in co-occurrence matrix: {co_matrix[word2idx['hello']]}\")\n",
    "print(f\"hello in PPMI: {output_ppmi[word2idx['hello']]}\")\n",
    "print(f\"hello in SVD: {U[word2idx['hello']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.52935042e-08  8.93084764e-01 -2.37586200e-08  8.93084824e-01\n",
      "   8.93084824e-01  4.47104114e-08  3.08122218e-01]\n",
      " [ 8.93084764e-01  1.92635028e-08  1.34603795e-08 -7.11651316e-09\n",
      "   1.45025325e-09  1.70043969e+00 -4.49460344e-08]\n",
      " [ 1.72256680e-08  1.35580214e-08  1.23703447e-08  1.78285688e-08\n",
      "   7.00439632e-01  7.00439751e-01  1.11547709e+00]\n",
      " [ 8.93084824e-01 -6.68377638e-08  1.77927717e-08 -1.76178805e-08\n",
      "  -5.30116395e-08 -5.17287262e-08  2.11547732e+00]\n",
      " [ 8.93084824e-01 -2.25320171e-08  7.00439632e-01 -2.39223930e-08\n",
      "  -8.11807155e-09  7.00439692e-01 -2.88939308e-08]\n",
      " [ 1.91322336e-09  1.70043981e+00  7.00439751e-01 -3.84810370e-08\n",
      "   7.00439692e-01  6.17670821e-08 -4.64926551e-08]\n",
      " [ 3.08122247e-01 -6.89178705e-08  1.11547709e+00  2.11547732e+00\n",
      "  -4.47034836e-08  1.49011612e-08 -2.98023224e-08]]\n",
      "[[0.        0.8930848 0.        0.8930848 0.8930848 0.        0.3081223]\n",
      " [0.8930848 0.        0.        0.        0.        1.7004397 0.       ]\n",
      " [0.        0.        0.        0.        0.7004397 0.7004397 1.1154772]\n",
      " [0.8930848 0.        0.        0.        0.        0.        2.1154773]\n",
      " [0.8930848 0.        0.7004397 0.        0.        0.7004397 0.       ]\n",
      " [0.        1.7004397 0.7004397 0.        0.7004397 0.        0.       ]\n",
      " [0.3081223 0.        1.1154772 2.1154773 0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# 檢查分解是否正確\n",
    "A = U @ np.diag(S) @ V\n",
    "print(A)\n",
    "print(output_ppmi)\n",
    "# 可以發先做完SVD得結果跟原來的output_ppmi是相同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9371588  2.5547988  2.1101685  1.9556583  1.1257027  0.58972406\n",
      " 0.30812874]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.3710324 , -0.26495245,  0.31999645,  0.0807369 ,  0.45295563,\n",
       "         0.4691856 ],\n",
       "       [-0.29432744,  0.29746115, -0.5294562 ,  0.511355  ,  0.22169203,\n",
       "         0.35262936],\n",
       "       [-0.33312967,  0.30777904,  0.16466641,  0.03673923,  0.5294517 ,\n",
       "        -0.6964652 ],\n",
       "       [-0.48203   ,  0.56445074,  0.26282662, -0.430857  , -0.33953863,\n",
       "         0.2642201 ],\n",
       "       [-0.26702777,  0.09261478, -0.3523957 ,  0.24547683, -0.44945022,\n",
       "        -0.26410997],\n",
       "       [-0.31352073, -0.30776063,  0.48896635,  0.5457005 , -0.38465765,\n",
       "        -0.12412582],\n",
       "       [-0.5126197 , -0.5698161 , -0.39725903, -0.4323913 , -0.01054526,\n",
       "        -0.124419  ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以發現前六個奇異值就佔了絕大多數的奇異值\n",
    "print(S)\n",
    "\n",
    "# 可以取前六個維度當作降為的詞向量\n",
    "U_reduce = U[:, 0:6]\n",
    "U_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 將詞向量降為二維方便視覺化\n",
    "U_visualization = U[:, 0:2]\n",
    "\n",
    "# visualization\n",
    "for word, word_id in word2idx.items():\n",
    "    plt.annotate(word, (U_reduce[word_id, 0], U_reduce[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U_reduce[:, 0], U_reduce[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
